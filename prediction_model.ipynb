{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from sklearn import ensemble    \n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('/home/shin/Documents/Data_mining/train.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/shin/Documents/Data_mining/train.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge = pd.read_csv('/home/shin/Documents/Data_mining/challenge.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data, challenge], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parsing Date and time (Seconds omited because they are all '0')\n",
    "import datetime\n",
    "date = data.Datum\n",
    "Year = []\n",
    "Month = []\n",
    "Day = []\n",
    "Hour = []\n",
    "Minute = []\n",
    "for i in date:\n",
    "    dateparse = datetime.datetime.strptime(i, \"%Y-%m-%d %H:%M:%S\")\n",
    "    Year.append(dateparse.year)\n",
    "    Month.append(dateparse.month)\n",
    "    Day.append(dateparse.day)\n",
    "    Hour.append(dateparse.hour)\n",
    "    Minute.append(dateparse.minute)\n",
    "data.insert(0, 'Year', Year)\n",
    "data.insert(1, 'Month', Month)\n",
    "data.insert(2, 'Day', Day)\n",
    "data.insert(3, 'Hour', Hour)\n",
    "data.insert(4, 'Min', Minute)\n",
    "data = data.drop(['Datum'], axis = 1)\n",
    "\n",
    "date_challenge = challenge.Datum\n",
    "Year_challenge = []\n",
    "Month_challenge = []\n",
    "Day_challenge = []\n",
    "Hour_challenge = []\n",
    "Minute_challenge = []\n",
    "for i in date_challenge:\n",
    "    dateparse_challenge = datetime.datetime.strptime(i, \"%Y-%m-%d %H:%M:%S\")\n",
    "    Year_challenge.append(dateparse_challenge.year)\n",
    "    Month_challenge.append(dateparse_challenge.month)\n",
    "    Day_challenge.append(dateparse_challenge.day)\n",
    "    Hour_challenge.append(dateparse_challenge.hour)\n",
    "    Minute_challenge.append(dateparse_challenge.minute)\n",
    "challenge.insert(0, 'Year', Year_challenge)\n",
    "challenge.insert(1, 'Month', Month_challenge)\n",
    "challenge.insert(2, 'Day', Day_challenge)\n",
    "challenge.insert(3, 'Hour', Hour_challenge)\n",
    "challenge.insert(4, 'Min', Minute_challenge)\n",
    "challenge = challenge.drop(['Datum'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Month', 'Day', 'Hour', 'Min', 'Windgeschwindigkeit48M',\n",
       "       'Windgeschwindigkeit100M', 'Windgeschwindigkeit152M', 'Windrichtung48M',\n",
       "       'Windrichtung100M', 'Windrichtung152M', 'Windgeschwindigkeit100MP10',\n",
       "       'Windgeschwindigkeit100MP20', 'Windgeschwindigkeit100MP30',\n",
       "       'Windgeschwindigkeit100MP40', 'Windgeschwindigkeit100MP50',\n",
       "       'Windgeschwindigkeit100MP60', 'Windgeschwindigkeit100MP70',\n",
       "       'Windgeschwindigkeit100MP80', 'Windgeschwindigkeit100MP90',\n",
       "       'Interpoliert', 'Verfügbare_Kapazität', 'Output'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does not improve the result\n",
    "# ratio = data.Output / data.Verfügbare_Kapazität\n",
    "# Windgeschwindigkeit48M_tanh = np.tanh(data.Windgeschwindigkeit48M)\n",
    "# Windgeschwindigkeit48M_log = np.log(data.Windgeschwindigkeit48M)\n",
    "# Windgeschwindigkeit100M_log = np.log(data.Windgeschwindigkeit100M)\n",
    "# Windgeschwindigkeit152M_log = np.log(data.Windgeschwindigkeit152M)\n",
    "# windspeed_sq = np.sqrt(windspeed_avg)\n",
    "# windspeed_log = np.log(windspeed_avg) \n",
    "# data.insert(11, 'windspeed_log', windspeed_log)\n",
    "# windspeed_tan = np.tanh(windspeed_avg)\n",
    "# windspeed_max = windspeed.max(axis = 1)\n",
    "# windspeedmp = data.loc[:len(data), 'Windgeschwindigkeit100MP10':'Windgeschwindigkeit100MP90']\n",
    "# windspeedmp_avg = windspeedmp.mean(axis = 1)\n",
    "# windspeedmp_sum = windspeedmp.sum(axis = 1)\n",
    "# windspeedmp_max = windspeedmp.max(axis = 1)\n",
    "# Windgeschwindigkeit100MP15 = data.loc[:len(data), 'Windgeschwindigkeit100MP10':'Windgeschwindigkeit100MP20'].mean(axis = 1)\n",
    "# Windgeschwindigkeit100MP25 = data.loc[:len(data), 'Windgeschwindigkeit100MP20':'Windgeschwindigkeit100MP30'].mean(axis = 1)\n",
    "# winddirection = data.loc[:len(data), 'Windrichtung48M':'Windrichtung152M'].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nseason = []\\nfor i in range(len(data)):\\n    if data.Month[i] == 4 or 5 or 6 or 7 or 8 or 9 or 10:\\n        season.append(0)\\n    else:\\n        season.append(1)\\ndata.insert(11, 'season', season)\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "season = []\n",
    "for i in range(len(data)):\n",
    "    if data.Month[i] == 4 or 5 or 6 or 7 or 8 or 9 or 10:\n",
    "        season.append(0)\n",
    "    else:\n",
    "        season.append(1)\n",
    "data.insert(11, 'season', season)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering \n",
    "# Windspeed average / SUM / ^2 ... (Coz they actually improved the result)\n",
    "windspeed = data.loc[:len(data), 'Windgeschwindigkeit48M':'Windgeschwindigkeit152M']\n",
    "windspeed_avg = windspeed.mean(axis = 1)\n",
    "windspeed_sum = windspeed.sum(axis = 1)\n",
    "Windgeschwindigkeit48M_2 = np.power(data.Windgeschwindigkeit48M, 2)\n",
    "Windgeschwindigkeit100M_2 = np.power(data.Windgeschwindigkeit100M, 2)\n",
    "Windgeschwindigkeit152M_2 = np.power(data.Windgeschwindigkeit152M, 2)\n",
    "data.insert(8, 'windspeed_avg', windspeed_avg)\n",
    "data.insert(9, 'windspeed_sum', windspeed_sum)\n",
    "data.insert(10, 'Windgeschwindigkeit48M_2', Windgeschwindigkeit48M_2)\n",
    "data.insert(11, 'Windgeschwindigkeit100M_2', Windgeschwindigkeit100M_2)\n",
    "data.insert(12, 'Windgeschwindigkeit152M_2', Windgeschwindigkeit152M_2)\n",
    "data = data.drop(['Windgeschwindigkeit100MP10','Windgeschwindigkeit100MP20','Windgeschwindigkeit100MP30','Windgeschwindigkeit100MP40','Windgeschwindigkeit100MP50','Windgeschwindigkeit100MP60','Windgeschwindigkeit100MP70','Windgeschwindigkeit100MP80','Windgeschwindigkeit100MP90'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_windspeed = challenge.loc[:len(challenge), 'Windgeschwindigkeit48M':'Windgeschwindigkeit152M']\n",
    "ch_windspeed_avg = ch_windspeed.mean(axis = 1)\n",
    "ch_windspeed_sum = ch_windspeed.sum(axis = 1)\n",
    "ch_Windgeschwindigkeit48M_2 = np.power(challenge.Windgeschwindigkeit48M, 2)\n",
    "ch_Windgeschwindigkeit100M_2 = np.power(challenge.Windgeschwindigkeit100M, 2)\n",
    "ch_Windgeschwindigkeit152M_2 = np.power(challenge.Windgeschwindigkeit152M, 2)\n",
    "challenge.insert(8, 'windspeed_avg', ch_windspeed_avg)\n",
    "challenge.insert(9, 'windspeed_sum', ch_windspeed_sum)\n",
    "challenge.insert(10, 'Windgeschwindigkeit48M_2', ch_Windgeschwindigkeit48M_2)\n",
    "challenge.insert(11, 'Windgeschwindigkeit100M_2', ch_Windgeschwindigkeit100M_2)\n",
    "challenge.insert(12, 'Windgeschwindigkeit152M_2', ch_Windgeschwindigkeit152M_2)\n",
    "challenge = challenge.drop(['Windgeschwindigkeit100MP10','Windgeschwindigkeit100MP20','Windgeschwindigkeit100MP30','Windgeschwindigkeit100MP40','Windgeschwindigkeit100MP50','Windgeschwindigkeit100MP60','Windgeschwindigkeit100MP70','Windgeschwindigkeit100MP80','Windgeschwindigkeit100MP90'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Month', 'Day', 'Hour', 'Min', 'Windgeschwindigkeit48M',\n",
       "       'Windgeschwindigkeit100M', 'Windgeschwindigkeit152M', 'windspeed_avg',\n",
       "       'windspeed_sum', 'Windgeschwindigkeit48M_2',\n",
       "       'Windgeschwindigkeit100M_2', 'Windgeschwindigkeit152M_2',\n",
       "       'Windrichtung48M', 'Windrichtung100M', 'Windrichtung152M',\n",
       "       'Interpoliert', 'Verfügbare_Kapazität', 'Output'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def Randomforest_original(X_train, y_train, X_test, depth):\n",
    "    rf_regr = RandomForestRegressor(max_depth=depth, random_state=rng, n_jobs=2)\n",
    "    rf_regr.fit(X_train, y_train)\n",
    "    y_pred = rf_regr.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = [1, 2, 4, 6, 8, 12,16, 24, 48, 96,144, 288, 400, 500, 672,960,1024, 1440, 1960, 2880, 4096, 8640, 12960, 17280]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interval = []\n",
    "#for i in range(1,130):\n",
    "#    interval.append(i**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_min = []\n",
    "for i in interval:\n",
    "    interval_min.append(int(i*15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = globals()\n",
    "variables = []\n",
    "for i, j in zip(interval, interval_min):\n",
    "    g[\"T_M{}\".format(j)] = data.Output.shift(i)\n",
    "    variables.append(\"T_M{}\".format(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_M15 added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_M30 added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_M60 added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_M90 added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_M120 added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_M180 added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_M240 added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_M360 added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_M720 added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_M1440 added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_M2160 added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_M4320 added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_M6000 added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_M7500 added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_M10080 added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_M14400 added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_M15360 added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_M21600 added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_M29400 added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_M43200 added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_M61440 added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_M129600 added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_M194400 added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_M259200 added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "tvc = 52507\n",
    "rng = np.random.RandomState(2028)\n",
    "for i,j,k,l in zip(interval, interval_min, variables, range(16,16+len(variables))):\n",
    "    X = scale(np.array(data.loc[:len(data),'Hour':'Interpoliert']))\n",
    "    X = X.astype(np.float32)\n",
    "    offset = int(X.shape[0] * 0.66)\n",
    "    X_train= X[:offset]\n",
    "    data.insert(l, \"T_M{}\".format(j), eval(k))\n",
    "    X_train,y_train = X[i:i+tvc], getattr(data, \"T_M%d\"%j)[i:i+tvc]\n",
    "    X_test, y_test = X[i+tvc:], getattr(data, \"T_M%d\"%j)[i+tvc:]\n",
    "    X_test2, y_test2 = X[:i], getattr(data, \"T_M%d\"%j)[:i]\n",
    "    getattr(data, \"T_M%d\"%j)[i+tvc:] = Randomforest_original(X_train, y_train, X_test, 9)\n",
    "    getattr(data, \"T_M%d\"%j)[:i] = Randomforest_original(X_train, y_train, X_test2, 9)\n",
    "    print(k, \"added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/shin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "#Data Split & Scaling\n",
    "X = scale(np.array(data.ix[:52507,'Hour':'Interpoliert']))\n",
    "y = np.array(data.Output.ix[:52507])\n",
    "X = X.astype(np.float32)\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "X_test, y_test = X[offset:], y[offset:]\n",
    "X_test_challenge = scale(np.array(data.ix[52508:,'Hour':'Interpoliert']))\n",
    "y_test_challenge = np.array(data.ix[52508:].Output)\n",
    "y_capacity = np.array(data.Verfügbare_Kapazität.ix[offset:52507])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Random Forest CV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def Randomforest_cv(Xtrain, ytrain, Xtest, ytest, ycapacity, depth):\n",
    "    rf_regr = RandomForestRegressor(max_depth=depth, random_state=rng)\n",
    "    rf_regr.fit(Xtrain, ytrain)\n",
    "    y_pred = rf_regr.predict(Xtest)\n",
    "    cape = sum(abs(y_pred - ytest))/sum(ycapacity)\n",
    "    print(\"Random Forest CAPE\", cape)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest CAPE 0.03615443479694251\n",
      "[10502 10503 10504 ... 52505 52506 52507] [    0     1     2 ... 10499 10500 10501]\n",
      "Random Forest CAPE 0.027414217145302504\n",
      "[    0     1     2 ... 52505 52506 52507] [10502 10503 10504 ... 21001 21002 21003]\n",
      "Random Forest CAPE 0.025610025966184682\n",
      "[    0     1     2 ... 52505 52506 52507] [21004 21005 21006 ... 31503 31504 31505]\n",
      "Random Forest CAPE 0.02604510402669217\n",
      "[    0     1     2 ... 52505 52506 52507] [31506 31507 31508 ... 42004 42005 42006]\n",
      "Random Forest CAPE 0.026720058368747933\n",
      "[    0     1     2 ... 42004 42005 42006] [42007 42008 42009 ... 52505 52506 52507]\n"
     ]
    }
   ],
   "source": [
    "rf_feature = []\n",
    "for i, j in kf.split(X):\n",
    "    rf_pred = Randomforest_cv(X[i], y[i], X[j], y[j], data.Verfügbare_Kapazität[j], 7)\n",
    "    print(i,j)\n",
    "    for k in rf_pred:\n",
    "        rf_feature.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Randomforest_ch(Xtrain, ytrain, Xtest, depth):\n",
    "    rf_regr = RandomForestRegressor(max_depth=depth, random_state=rng)\n",
    "    rf_regr.fit(Xtrain, ytrain)\n",
    "    y_pred = rf_regr.predict(Xtest)\n",
    "    return list(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_challenge = Randomforest_ch(X, y, X_test_challenge, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.insert(16, 'RandomForest', rf_feature + rf_challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#Data Split & Scaling\n",
    "X = scale(np.array(data.ix[:52507,'Hour':'Interpoliert']))\n",
    "y = np.array(data.Output.ix[:52507])\n",
    "X = X.astype(np.float32)\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "X_test, y_test = X[offset:], y[offset:]\n",
    "X_test_challenge = scale(np.array(data.ix[52508:,'Hour':'Interpoliert']))\n",
    "y_test_challenge = np.array(data.ix[52508:].Output)\n",
    "y_capacity = np.array(data.Verfügbare_Kapazität.ix[offset:52507])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Linear Regression CV\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "def LinearRegression_cv(Xtrain, ytrain, Xtest, ytest, ycapacity):\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(Xtrain, ytrain)\n",
    "    y_pred = regr.predict(Xtest)    \n",
    "    cape = sum(abs(y_pred - ytest))/sum(ycapacity)\n",
    "    print(\"Linear Regression CAPE /  Original Training Data / 10% Test data: \", cape)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression CAPE /  Original Training Data / 10% Test data:  0.03430830541997546\n",
      "[10502 10503 10504 ... 52505 52506 52507] [    0     1     2 ... 10499 10500 10501]\n",
      "Linear Regression CAPE /  Original Training Data / 10% Test data:  0.02721329957135947\n",
      "[    0     1     2 ... 52505 52506 52507] [10502 10503 10504 ... 21001 21002 21003]\n",
      "Linear Regression CAPE /  Original Training Data / 10% Test data:  0.0253889233514817\n",
      "[    0     1     2 ... 52505 52506 52507] [21004 21005 21006 ... 31503 31504 31505]\n",
      "Linear Regression CAPE /  Original Training Data / 10% Test data:  0.026340918124590766\n",
      "[    0     1     2 ... 52505 52506 52507] [31506 31507 31508 ... 42004 42005 42006]\n",
      "Linear Regression CAPE /  Original Training Data / 10% Test data:  0.02674313023092734\n",
      "[    0     1     2 ... 42004 42005 42006] [42007 42008 42009 ... 52505 52506 52507]\n"
     ]
    }
   ],
   "source": [
    "lr_feature = []\n",
    "for i, j in kf.split(X):\n",
    "    lr_pred = LinearRegression_cv(X[i], y[i], X[j], y[j], data.Verfügbare_Kapazität[j])\n",
    "    print(i,j)\n",
    "    for k in lr_pred:\n",
    "        lr_feature.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearRegression_ch(Xtrain, ytrain, Xtest):\n",
    "    lr_regr = linear_model.LinearRegression()\n",
    "    lr_regr.fit(Xtrain, ytrain)\n",
    "    y_pred = lr_regr.predict(Xtest)\n",
    "    return list(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_challenge = LinearRegression_ch(X, y, X_test_challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.insert(17, 'Linear', lr_feature + lr_challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#Data Split & Scaling\n",
    "X = scale(np.array(data.ix[:52507,'Hour':'Interpoliert']))\n",
    "y = np.array(data.Output.ix[:52507])\n",
    "X = X.astype(np.float32)\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "X_test, y_test = X[offset:], y[offset:]\n",
    "X_test_challenge = scale(np.array(data.ix[52508:,'Hour':'Interpoliert']))\n",
    "y_test_challenge = np.array(data.ix[52508:].Output)\n",
    "y_capacity = np.array(data.Verfügbare_Kapazität.ix[offset:52507])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Month', 'Day', 'Hour', 'Min', 'Windgeschwindigkeit48M',\n",
       "       'Windgeschwindigkeit100M', 'Windgeschwindigkeit152M', 'windspeed_avg',\n",
       "       'windspeed_sum', 'Windgeschwindigkeit48M_2',\n",
       "       'Windgeschwindigkeit100M_2', 'Windgeschwindigkeit152M_2',\n",
       "       'Windrichtung48M', 'Windrichtung100M', 'Windrichtung152M',\n",
       "       'RandomForest', 'Linear', 'T_M15', 'T_M30', 'T_M60', 'T_M90', 'T_M120',\n",
       "       'T_M180', 'T_M240', 'T_M360', 'T_M720', 'T_M1440', 'T_M2160', 'T_M4320',\n",
       "       'T_M6000', 'T_M7500', 'T_M10080', 'T_M14400', 'T_M15360', 'T_M21600',\n",
       "       'T_M29400', 'T_M43200', 'T_M61440', 'T_M129600', 'T_M194400',\n",
       "       'T_M259200', 'Interpoliert', 'Verfügbare_Kapazität', 'Output'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Decision Tree Regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "def Decisiontree_cv(Xtrain, ytrain, Xtest, ytest, ycapacity, depth):\n",
    "    regr = DecisionTreeRegressor(max_depth=depth)\n",
    "    regr.fit(Xtrain, ytrain)\n",
    "    y_pred = regr.predict(Xtest)\n",
    "    cape = sum(abs(y_pred - ytest))/sum(ycapacity)\n",
    "    print(\"Decision Tree / 5 fold CV \", cape)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree / 5 fold CV  0.03633095605416804\n",
      "[10502 10503 10504 ... 52505 52506 52507] [    0     1     2 ... 10499 10500 10501]\n",
      "Decision Tree / 5 fold CV  0.027804447346894967\n",
      "[    0     1     2 ... 52505 52506 52507] [10502 10503 10504 ... 21001 21002 21003]\n",
      "Decision Tree / 5 fold CV  0.025466115056470666\n",
      "[    0     1     2 ... 52505 52506 52507] [21004 21005 21006 ... 31503 31504 31505]\n",
      "Decision Tree / 5 fold CV  0.027714764203930216\n",
      "[    0     1     2 ... 52505 52506 52507] [31506 31507 31508 ... 42004 42005 42006]\n",
      "Decision Tree / 5 fold CV  0.026906543013336007\n",
      "[    0     1     2 ... 42004 42005 42006] [42007 42008 42009 ... 52505 52506 52507]\n"
     ]
    }
   ],
   "source": [
    "dt_feature = []\n",
    "for i, j in kf.split(X):\n",
    "    dt_pred = Decisiontree_cv(X[i], y[i], X[j], y[j], data.Verfügbare_Kapazität[j], 7)\n",
    "    print(i,j)\n",
    "    for k in dt_pred:\n",
    "        dt_feature.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decisiontree_ch(Xtrain, ytrain, Xtest, depth):\n",
    "    dt_regr = DecisionTreeRegressor(max_depth=depth)\n",
    "    dt_regr.fit(Xtrain, ytrain)\n",
    "    y_pred = dt_regr.predict(Xtest)\n",
    "    return list(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_challenge = Decisiontree_ch(X, y, X_test_challenge, 7)\n",
    "data.insert(18, 'DecisionTree', dt_feature + dt_challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#Data Split & Scaling\n",
    "X = scale(np.array(data.ix[:52507,'Hour':'Interpoliert']))\n",
    "y = np.array(data.Output.ix[:52507])\n",
    "X = X.astype(np.float32)\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "X_test, y_test = X[offset:], y[offset:]\n",
    "X_test_challenge = scale(np.array(data.ix[52508:,'Hour':'Interpoliert']))\n",
    "y_test_challenge = np.array(data.ix[52508:].Output)\n",
    "y_capacity = np.array(data.Verfügbare_Kapazität.ix[offset:52507])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Bagging regression\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "def bagging_cv(Xtrain, ytrain, Xtest, ytest, ycapacity):\n",
    "    bag = BaggingRegressor(n_estimators=5,random_state=rng,n_jobs=2)\n",
    "    y_pred_bag = bag.fit(Xtrain, ytrain).predict(Xtest)\n",
    "    cape = sum(abs(y_pred_bag - ytest))/sum(ycapacity)\n",
    "    print(\"Bagging CAPE /  Original Training Data / 10% Test data: \", cape)\n",
    "    return y_pred_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging CAPE /  Original Training Data / 10% Test data:  0.04034626435968392\n",
      "[10502 10503 10504 ... 52505 52506 52507] [    0     1     2 ... 10499 10500 10501]\n",
      "Bagging CAPE /  Original Training Data / 10% Test data:  0.030683998190229676\n",
      "[    0     1     2 ... 52505 52506 52507] [10502 10503 10504 ... 21001 21002 21003]\n",
      "Bagging CAPE /  Original Training Data / 10% Test data:  0.027949829209734232\n",
      "[    0     1     2 ... 52505 52506 52507] [21004 21005 21006 ... 31503 31504 31505]\n",
      "Bagging CAPE /  Original Training Data / 10% Test data:  0.03377557320242108\n",
      "[    0     1     2 ... 52505 52506 52507] [31506 31507 31508 ... 42004 42005 42006]\n",
      "Bagging CAPE /  Original Training Data / 10% Test data:  0.03006581149627064\n",
      "[    0     1     2 ... 42004 42005 42006] [42007 42008 42009 ... 52505 52506 52507]\n"
     ]
    }
   ],
   "source": [
    "bg_feature = []\n",
    "for i, j in kf.split(X):\n",
    "    bg_pred = bagging_cv(X[i], y[i], X[j], y[j], data.Verfügbare_Kapazität[j])\n",
    "    print(i,j)\n",
    "    for k in bg_pred:\n",
    "        bg_feature.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging_ch(Xtrain, ytrain, Xtest):\n",
    "    bag = BaggingRegressor(n_estimators=5,random_state=rng,n_jobs=2)\n",
    "    y_pred_bag = bag.fit(Xtrain, ytrain).predict(Xtest)\n",
    "    return list(y_pred_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_challenge = bagging_ch(X, y, X_test_challenge)\n",
    "data.insert(19, 'Bagging', bg_feature + bg_challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#Data Split & Scaling\n",
    "X = scale(np.array(data.ix[:52507,'Hour':'Interpoliert']))\n",
    "y = np.array(data.Output.ix[:52507])\n",
    "X = X.astype(np.float32)\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "X_test, y_test = X[offset:], y[offset:]\n",
    "X_test_challenge = scale(np.array(data.ix[52508:,'Hour':'Interpoliert']))\n",
    "y_test_challenge = np.array(data.ix[52508:].Output)\n",
    "y_capacity = np.array(data.Verfügbare_Kapazität.ix[offset:52507])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 MLP Regressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "def mlp_cv(Xtrain, ytrain, Xtest, ytest, ycapacity):\n",
    "    reg = MLPRegressor(hidden_layer_sizes=(10,),  activation='relu', solver='adam',    alpha=0.01,batch_size='auto',\n",
    "               learning_rate='constant', learning_rate_init=0.05, power_t=0.5, max_iter=1000, tol=0.0001, verbose=False, warm_start=False, momentum=0.9,\n",
    "               nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999,\n",
    "               epsilon=1e-08)\n",
    "\n",
    "    mlp = reg.fit(Xtrain, ytrain)\n",
    "    y_pred = mlp.predict(Xtest)\n",
    "    try:\n",
    "        cape = sum(abs(y_pred - ytest))/sum(ycapacity)\n",
    "        print(\"CNN CAPE /  Original Training Data / 10% Test data: \", cape)\n",
    "    except:\n",
    "        pass\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN CAPE /  Original Training Data / 10% Test data:  0.03728438603012265\n",
      "[10502 10503 10504 ... 52505 52506 52507] [    0     1     2 ... 10499 10500 10501]\n",
      "CNN CAPE /  Original Training Data / 10% Test data:  0.02738091732107605\n",
      "[    0     1     2 ... 52505 52506 52507] [10502 10503 10504 ... 21001 21002 21003]\n",
      "CNN CAPE /  Original Training Data / 10% Test data:  0.02586152193086152\n",
      "[    0     1     2 ... 52505 52506 52507] [21004 21005 21006 ... 31503 31504 31505]\n",
      "CNN CAPE /  Original Training Data / 10% Test data:  0.027961062545496487\n",
      "[    0     1     2 ... 52505 52506 52507] [31506 31507 31508 ... 42004 42005 42006]\n",
      "CNN CAPE /  Original Training Data / 10% Test data:  0.026964876911430766\n",
      "[    0     1     2 ... 42004 42005 42006] [42007 42008 42009 ... 52505 52506 52507]\n"
     ]
    }
   ],
   "source": [
    "mlp_feature = []\n",
    "for i, j in kf.split(X):\n",
    "    mlp_pred = mlp_cv(X[i], y[i], X[j], y[j], data.Verfügbare_Kapazität[j])\n",
    "    print(i,j)\n",
    "    for k in mlp_pred:\n",
    "         mlp_feature.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_ch(Xtrain, ytrain, Xtest):\n",
    "    reg = MLPRegressor(hidden_layer_sizes=(10,),  activation='relu', solver='adam',    alpha=0.01,batch_size='auto',\n",
    "               learning_rate='constant', learning_rate_init=0.05, power_t=0.5, max_iter=1000, tol=0.0001, verbose=False, warm_start=False, momentum=0.9,\n",
    "               nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999,\n",
    "               epsilon=1e-08)\n",
    "    mlp = reg.fit(Xtrain, ytrain)\n",
    "    y_pred = mlp.predict(Xtest)\n",
    "    return list(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_challenge = mlp_ch(X, y, X_test_challenge)\n",
    "data.insert(20, 'MLP', mlp_feature + mlp_challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#Data Split & Scaling\n",
    "X = scale(np.array(data.ix[:52507,'Hour':'Interpoliert']))\n",
    "y = np.array(data.Output.ix[:52507])\n",
    "X = X.astype(np.float32)\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "X_test, y_test = X[offset:], y[offset:]\n",
    "X_test_challenge = scale(np.array(data.ix[52508:,'Hour':'Interpoliert']))\n",
    "y_test_challenge = np.array(data.ix[52508:].Output)\n",
    "y_capacity = np.array(data.Verfügbare_Kapazität.ix[offset:52507])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 Ridge Regrssion\n",
    "from sklearn.linear_model import Ridge\n",
    "def ridge_cv(Xtrain, ytrain, Xtest, ytest, ycapacity):\n",
    "    clf = Ridge(alpha=1.0)\n",
    "    clf.fit(Xtrain, ytrain)\n",
    "    y_ridge_pred = clf.predict(Xtest)\n",
    "    cape = sum(abs(y_ridge_pred - ytest))/sum(ycapacity)\n",
    "    print(\"Ridge CAPE /  Original Training Data / 10% Test data: \", cape)\n",
    "    return y_ridge_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge CAPE /  Original Training Data / 10% Test data:  0.034672688482883844\n",
      "[10502 10503 10504 ... 52505 52506 52507] [    0     1     2 ... 10499 10500 10501]\n",
      "Ridge CAPE /  Original Training Data / 10% Test data:  0.026870846981680956\n",
      "[    0     1     2 ... 52505 52506 52507] [10502 10503 10504 ... 21001 21002 21003]\n",
      "Ridge CAPE /  Original Training Data / 10% Test data:  0.025051397930423037\n",
      "[    0     1     2 ... 52505 52506 52507] [21004 21005 21006 ... 31503 31504 31505]\n",
      "Ridge CAPE /  Original Training Data / 10% Test data:  0.025924727936308185\n",
      "[    0     1     2 ... 52505 52506 52507] [31506 31507 31508 ... 42004 42005 42006]\n",
      "Ridge CAPE /  Original Training Data / 10% Test data:  0.026136411923600094\n",
      "[    0     1     2 ... 42004 42005 42006] [42007 42008 42009 ... 52505 52506 52507]\n"
     ]
    }
   ],
   "source": [
    "ridge_feature = []\n",
    "for i, j in kf.split(X):\n",
    "    ridge_pred = ridge_cv(X[i], y[i], X[j], y[j], data.Verfügbare_Kapazität[j])\n",
    "    print(i,j)\n",
    "    for k in ridge_pred:\n",
    "         ridge_feature.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_ch(Xtrain, ytrain, Xtest):\n",
    "    clf = Ridge(alpha=1.0)\n",
    "    clf.fit(Xtrain, ytrain)\n",
    "    y_ridge_pred = clf.predict(Xtest)\n",
    "    return list(y_ridge_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_challenge = ridge_ch(X, y, X_test_challenge)\n",
    "data.insert(21, 'Ridge', ridge_feature + ridge_challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#Data Split & Scaling\n",
    "X = scale(np.array(data.ix[:52507,'Hour':'Interpoliert']))\n",
    "y = np.array(data.Output.ix[:52507])\n",
    "X = X.astype(np.float32)\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "X_test, y_test = X[offset:], y[offset:]\n",
    "X_test_challenge = scale(np.array(data.ix[52508:,'Hour':'Interpoliert']))\n",
    "y_test_challenge = np.array(data.ix[52508:].Output)\n",
    "y_capacity = np.array(data.Verfügbare_Kapazität.ix[offset:52507])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 Light GBM CV\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.01, n_estimators=1000,\n",
    "                              max_bin = 30, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "def lgb_cv(Xtrain, ytrain, Xtest, ytest, ycapacity):\n",
    "    model_lgb.fit(Xtrain, ytrain)\n",
    "    lgb_pred = model_lgb.predict(Xtest)\n",
    "    cape = sum(abs(lgb_pred - ytest))/sum(ycapacity)\n",
    "    print(\"LightGBM CAPE /  Training Data 90% / 10% Test data: \", cape)\n",
    "    return lgb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM CAPE /  Training Data 90% / 10% Test data:  0.038831468370932626\n",
      "[10502 10503 10504 ... 52505 52506 52507] [    0     1     2 ... 10499 10500 10501]\n",
      "LightGBM CAPE /  Training Data 90% / 10% Test data:  0.027769126047329905\n",
      "[    0     1     2 ... 52505 52506 52507] [10502 10503 10504 ... 21001 21002 21003]\n",
      "LightGBM CAPE /  Training Data 90% / 10% Test data:  0.025956361160027194\n",
      "[    0     1     2 ... 52505 52506 52507] [21004 21005 21006 ... 31503 31504 31505]\n",
      "LightGBM CAPE /  Training Data 90% / 10% Test data:  0.028998705699038542\n",
      "[    0     1     2 ... 52505 52506 52507] [31506 31507 31508 ... 42004 42005 42006]\n",
      "LightGBM CAPE /  Training Data 90% / 10% Test data:  0.027153381133527704\n",
      "[    0     1     2 ... 42004 42005 42006] [42007 42008 42009 ... 52505 52506 52507]\n"
     ]
    }
   ],
   "source": [
    "lgb_feature = []\n",
    "for i, j in kf.split(X):\n",
    "    lgb_pred = lgb_cv(X[i], y[i], X[j], y[j], data.Verfügbare_Kapazität[j])\n",
    "    print(i,j)\n",
    "    for k in lgb_pred:\n",
    "         lgb_feature.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_ch(Xtrain, ytrain, Xtest):\n",
    "    model_lgb.fit(Xtrain, ytrain)\n",
    "    lgb_pred = model_lgb.predict(Xtest)\n",
    "    return list(lgb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_challenge = lgb_ch(X, y, X_test_challenge)\n",
    "data.insert(22, 'LGB', lgb_feature + lgb_challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#Data Split & Scaling\n",
    "X = scale(np.array(data.ix[:52507,'Hour':'Interpoliert']))\n",
    "y = np.array(data.Output.ix[:52507])\n",
    "X = X.astype(np.float32)\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "X_test, y_test = X[offset:], y[offset:]\n",
    "X_test_challenge = scale(np.array(data.ix[52508:,'Hour':'Interpoliert']))\n",
    "y_test_challenge = np.array(data.ix[52508:].Output)\n",
    "y_capacity = np.array(data.Verfügbare_Kapazität.ix[offset:52507])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8 XGboost\n",
    "import xgboost as xgb\n",
    "def xgb_cv(Xtrain, ytrain, Xtest, ytest, ycapacity):\n",
    "    gbm = xgb.XGBRegressor(max_depth=4, n_estimators=500, learning_rate=0.01).fit(Xtrain, ytrain)\n",
    "    predictions = gbm.predict(Xtest)\n",
    "    cape = sum(abs(predictions - ytest))/sum(ycapacity)\n",
    "    print(\"XGBoost CAPE /  Original Training Data / 10% Test data: \", cape)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost CAPE /  Original Training Data / 10% Test data:  0.03579052125043428\n",
      "[10502 10503 10504 ... 52505 52506 52507] [    0     1     2 ... 10499 10500 10501]\n",
      "XGBoost CAPE /  Original Training Data / 10% Test data:  0.027221050762672346\n",
      "[    0     1     2 ... 52505 52506 52507] [10502 10503 10504 ... 21001 21002 21003]\n",
      "XGBoost CAPE /  Original Training Data / 10% Test data:  0.02503978015280855\n",
      "[    0     1     2 ... 52505 52506 52507] [21004 21005 21006 ... 31503 31504 31505]\n",
      "XGBoost CAPE /  Original Training Data / 10% Test data:  0.027178839254272672\n",
      "[    0     1     2 ... 52505 52506 52507] [31506 31507 31508 ... 42004 42005 42006]\n",
      "XGBoost CAPE /  Original Training Data / 10% Test data:  0.026198648633565563\n",
      "[    0     1     2 ... 42004 42005 42006] [42007 42008 42009 ... 52505 52506 52507]\n"
     ]
    }
   ],
   "source": [
    "xgb_feature = []\n",
    "for i, j in kf.split(X):\n",
    "    xgb_pred = xgb_cv(X[i], y[i], X[j], y[j], data.Verfügbare_Kapazität[j])\n",
    "    print(i,j)\n",
    "    for k in xgb_pred:\n",
    "         xgb_feature.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_ch(Xtrain, ytrain, Xtest):\n",
    "    gbm = xgb.XGBRegressor(max_depth=4, n_estimators=500, learning_rate=0.01).fit(Xtrain, ytrain)\n",
    "    predictions = gbm.predict(Xtest)\n",
    "    return list(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_challenge = xgb_ch(X, y, X_test_challenge)\n",
    "data.insert(23, 'XGB', xgb_feature + xgb_challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#Data Split & Scaling\n",
    "X = scale(np.array(data.ix[:52507,'Hour':'Interpoliert']))\n",
    "y = np.array(data.Output.ix[:52507])\n",
    "X = X.astype(np.float32)\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "X_test, y_test = X[offset:], y[offset:]\n",
    "X_test_challenge = scale(np.array(data.ix[52508:,'Hour':'Interpoliert']))\n",
    "y_test_challenge = np.array(data.ix[52508:].Output)\n",
    "y_capacity = np.array(data.Verfügbare_Kapazität.ix[offset:52507])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9 ElasticNet\n",
    "from sklearn.linear_model import ElasticNet\n",
    "def enet_cv(Xtrain, ytrain, Xtest, ytest, ycapacity):\n",
    "    alpha = 0.63\n",
    "    enet = ElasticNet(alpha=alpha, l1_ratio=0.35)\n",
    "    y_pred_enet = enet.fit(Xtrain, ytrain).predict(Xtest)\n",
    "    cape = sum(abs(y_pred_enet - ytest))/sum(ycapacity)\n",
    "    print(\"ElasticNet CAPE /  Original Training Data / 10% Test data: \", cape)\n",
    "    return y_pred_enet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet CAPE /  Original Training Data / 10% Test data:  0.03988317060912024\n",
      "[10502 10503 10504 ... 52505 52506 52507] [    0     1     2 ... 10499 10500 10501]\n",
      "ElasticNet CAPE /  Original Training Data / 10% Test data:  0.030684938912320985\n",
      "[    0     1     2 ... 52505 52506 52507] [10502 10503 10504 ... 21001 21002 21003]\n",
      "ElasticNet CAPE /  Original Training Data / 10% Test data:  0.029257475282886244\n",
      "[    0     1     2 ... 52505 52506 52507] [21004 21005 21006 ... 31503 31504 31505]\n",
      "ElasticNet CAPE /  Original Training Data / 10% Test data:  0.03368641801021693\n",
      "[    0     1     2 ... 52505 52506 52507] [31506 31507 31508 ... 42004 42005 42006]\n",
      "ElasticNet CAPE /  Original Training Data / 10% Test data:  0.031149257398700607\n",
      "[    0     1     2 ... 42004 42005 42006] [42007 42008 42009 ... 52505 52506 52507]\n"
     ]
    }
   ],
   "source": [
    "enet_feature = []\n",
    "for i, j in kf.split(X):\n",
    "    enet_pred = enet_cv(X[i], y[i], X[j], y[j], data.Verfügbare_Kapazität[j])\n",
    "    print(i,j)\n",
    "    for k in enet_pred:\n",
    "         enet_feature.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enet_ch(Xtrain, ytrain, Xtest):\n",
    "    alpha = 0.63\n",
    "    enet = ElasticNet(alpha=alpha, l1_ratio=0.35)\n",
    "    y_pred_enet = enet.fit(Xtrain, ytrain).predict(Xtest)\n",
    "    return list(y_pred_enet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet_challenge = enet_ch(X, y, X_test_challenge)\n",
    "# data.insert(24, 'Enet', enet_feature + enet_challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#Data Split & Scaling\n",
    "X = scale(np.array(data.ix[:52507,'Hour':'Interpoliert']))\n",
    "y = np.array(data.Output.ix[:52507])\n",
    "X = X.astype(np.float32)\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "X_test, y_test = X[offset:], y[offset:]\n",
    "X_test_challenge = scale(np.array(data.ix[52508:,'Hour':'Interpoliert']))\n",
    "y_test_challenge = np.array(data.ix[52508:].Output)\n",
    "y_capacity = np.array(data.Verfügbare_Kapazität.ix[offset:52507])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9 Random Forest 2 CV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def Randomforest_cv2(Xtrain, ytrain, Xtest, ytest, ycapacity, depth):\n",
    "    rf_regr = RandomForestRegressor(max_depth=depth, random_state=rng)\n",
    "    rf_regr.fit(Xtrain, ytrain)\n",
    "    y_pred = rf_regr.predict(Xtest)\n",
    "    cape = sum(abs(y_pred - ytest))/sum(ycapacity)\n",
    "    print(\"Random Forest CAPE\", cape)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest CAPE 0.0369759934396712\n",
      "[10502 10503 10504 ... 52505 52506 52507] [    0     1     2 ... 10499 10500 10501]\n",
      "Random Forest CAPE 0.027451473056381393\n",
      "[    0     1     2 ... 52505 52506 52507] [10502 10503 10504 ... 21001 21002 21003]\n",
      "Random Forest CAPE 0.024923240777336854\n",
      "[    0     1     2 ... 52505 52506 52507] [21004 21005 21006 ... 31503 31504 31505]\n",
      "Random Forest CAPE 0.029076042228365444\n",
      "[    0     1     2 ... 52505 52506 52507] [31506 31507 31508 ... 42004 42005 42006]\n",
      "Random Forest CAPE 0.02651507204162057\n",
      "[    0     1     2 ... 42004 42005 42006] [42007 42008 42009 ... 52505 52506 52507]\n"
     ]
    }
   ],
   "source": [
    "rf_feature2 = []\n",
    "for i, j in kf.split(X):\n",
    "    rf_pred = Randomforest_cv2(X[i], y[i], X[j], y[j], data.Verfügbare_Kapazität[j], 9)\n",
    "    print(i,j)\n",
    "    for k in rf_pred:\n",
    "        rf_feature2.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Randomforest_ch2(Xtrain, ytrain, Xtest, depth):\n",
    "    rf_regr = RandomForestRegressor(max_depth=depth, random_state=rng)\n",
    "    rf_regr.fit(Xtrain, ytrain)\n",
    "    y_pred = rf_regr.predict(Xtest)\n",
    "    return list(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_challenge2 = Randomforest_ch2(X, y, X_test_challenge, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.insert(24, 'RandomForest2', rf_feature2 + rf_challenge2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#Data Split & Scaling\n",
    "X = scale(np.array(data.ix[:52507,'Hour':'Interpoliert']))\n",
    "y = np.array(data.Output.ix[:52507])\n",
    "X = X.astype(np.float32)\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "X_test, y_test = X[offset:], y[offset:]\n",
    "X_test_challenge = scale(np.array(data.ix[52508:,'Hour':'Interpoliert']))\n",
    "y_test_challenge = np.array(data.ix[52508:].Output)\n",
    "y_capacity = np.array(data.Verfügbare_Kapazität.ix[offset:52507])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.03, n_estimators=1000,\n",
    "                              max_bin = 30, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "def lightgbm(Xtrain, ytrain, Xtest, ytest, ycapacity):\n",
    "    model_lgb.fit(Xtrain, ytrain)\n",
    "    lgb_pred = model_lgb.predict(Xtest)\n",
    "    cape = sum(abs(lgb_pred - ytest))/sum(ycapacity)\n",
    "    print(\"LightGBM CAPE /  Training Data 90% / 10% Test data: \", cape)\n",
    "    return lgb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM CAPE /  Training Data 90% / 10% Test data:  0.0244407730578272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 7262.05804327,  8299.31304279,  7800.20258187, ...,\n",
       "       17290.71235591, 17543.4277966 , 14862.77566938])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lightgbm(X_train, y_train, X_test, y_test, y_capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM CAPE /  Training Data 90% / 10% Test data:  0.0244407730578272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 7262.05804327,  8299.31304279,  7800.20258187, ...,\n",
       "       17290.71235591, 17543.4277966 , 14862.77566938])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lightgbm(X_train, y_train, X_test, y_test, y_capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost CAPE /  Original Training Data / 10% Test data:  0.023967201870621468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 7714.0776,  8915.644 ,  8292.856 , ..., 18210.139 , 18690.375 ,\n",
       "       15037.096 ], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def xgb_cv(Xtrain, ytrain, Xtest, ytest, ycapacity):\n",
    "    gbm = xgb.XGBRegressor(max_depth=7, n_estimators=1000, learning_rate=0.01).fit(Xtrain, ytrain)\n",
    "    predictions = gbm.predict(Xtest)\n",
    "    cape = sum(abs(predictions - ytest))/sum(ycapacity)\n",
    "    print(\"XGBoost CAPE /  Original Training Data / 10% Test data: \", cape)\n",
    "    return predictions\n",
    "xgb_cv(X_train, y_train, X_test, y_test, y_capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest CAPE 0.024376032519876877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 7815.05474824,  9061.73323667,  8428.67375235, ...,\n",
       "       17540.04548426, 18183.72102714, 14904.44434258])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Randomforest_cv(X_train, y_train, X_test, y_test, y_capacity, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lightgbm 0.024413401288697217\n",
    "#Random Forest 0.02407022221515361\n",
    "#MLP 0.024730823589527717\n",
    "#XGB  0.024175183128886082 depth =4, n=500 lr = 0.01\n",
    "#XGB  0.02404250686442158 depth =4, n=1000 lr = 0.01\n",
    "#XGB 0.02405902502124753 depth =4, n= 1000 lr = 0.03\n",
    "#XGB 0.024376032519876877 depth =4, n= 1300 lr = 0.01\n",
    "#XGB 0.02403249765675427 depth =5, n= 1000 lr = 0.03\n",
    "#XGB 0.02399690647455083 max_depth=6, n_estimators=1000, learning_rate=0.01\n",
    "#XGB 0.0240423412097441 max_depth=6, n_estimators=1000, learning_rate=0.005\n",
    "#XGB 0.023967201870621468 max_depth=7, n_estimators=1000, learning_rate=0.01\n",
    "#XGB  0.024362709992839744 max_depth=9, n_estimators=1000, learning_rate=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN CAPE /  Original Training Data / 10% Test data:  0.02459076294986711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 7252.97404195,  8263.776241  ,  7854.68156657, ...,\n",
       "       18168.1848841 , 18526.32180454, 15778.64069757])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_cv(X_train, y_train, X_test, y_test, y_capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightgbm_challenge(Xtrain, ytrain, Xtest):\n",
    "    model_lgb.fit(Xtrain, ytrain)\n",
    "    lgb_pred = model_lgb.predict(Xtest)\n",
    "    return lgb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_challenge(Xtrain, ytrain, Xtest):\n",
    "    gbm = xgb.XGBRegressor(max_depth=7, n_estimators=1000, learning_rate=0.005).fit(Xtrain, ytrain)\n",
    "    predictions = gbm.predict(Xtest)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-6750be27442c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_challenge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-113-fdb068673b5a>\u001b[0m in \u001b[0;36mxgb_challenge\u001b[0;34m(Xtrain, ytrain, Xtest)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mxgb_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mgbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit)\u001b[0m\n\u001b[1;32m    310\u001b[0m         return self.get_booster().predict(test_dmatrix,\n\u001b[1;32m    311\u001b[0m                                           \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                                           ntree_limit=ntree_limit)\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs)\u001b[0m\n\u001b[1;32m   1050\u001b[0m                                           \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_uint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m                                           \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m                                           ctypes.byref(preds)))\n\u001b[0m\u001b[1;32m   1053\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes2numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "submission = xgb_challenge(X, y, X_test_challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge2 = pd.read_csv('/home/shin/Documents/Data_mining/challenge.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge2.Output = submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge2.to_csv(\"submission8-1.csv\", sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:52508].to_csv(\"training_stacking.csv\", sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[52508:].to_csv(\"challenge_stacking.csv\", sep=',', index=False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"alldata.csv\", sep=',', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
